{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Complete Accuracy Evaluation Pipeline - Kaggle Edition\n## Day 2: Independent Accuracy Measurement System\n\n**Purpose:** Evaluate model accuracy for FP32, FP16, INT8 independently of energy measurements\n\n**Works NOW for:** FP32 baseline  \n**Ready for:** FP16/INT8 when Thomas provides models  \n**Integrates with:** Krishna's energy data when available\n\n---\n\n**Run this notebook to:**\n1. Evaluate model accuracy\n2. Generate confusion matrices\n3. Compute per-class statistics\n4. Log results to CSV\n5. Compare multiple precisions","metadata":{}},{"cell_type":"markdown","source":"## Part 1: Setup and Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers datasets scikit-learn seaborn\n\nprint(\"Dependencies installed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:30.118939Z","iopub.execute_input":"2025-12-01T19:34:30.119236Z","iopub.status.idle":"2025-12-01T19:34:33.721607Z","shell.execute_reply.started":"2025-12-01T19:34:30.119215Z","shell.execute_reply":"2025-12-01T19:34:33.720665Z"}},"outputs":[{"name":"stdout","text":"Dependencies installed\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport json\nimport time\nfrom datetime import datetime\nfrom dataclasses import dataclass, asdict\nfrom typing import Dict, List, Optional\n\nfrom transformers import DistilBertForSequenceClassification\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nprint(\"All imports successful\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:33.723293Z","iopub.execute_input":"2025-12-01T19:34:33.723578Z","iopub.status.idle":"2025-12-01T19:34:33.729086Z","shell.execute_reply.started":"2025-12-01T19:34:33.723552Z","shell.execute_reply":"2025-12-01T19:34:33.728214Z"}},"outputs":[{"name":"stdout","text":"All imports successful\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:33.729721Z","iopub.execute_input":"2025-12-01T19:34:33.730067Z","iopub.status.idle":"2025-12-01T19:34:34.048105Z","shell.execute_reply.started":"2025-12-01T19:34:33.730043Z","shell.execute_reply":"2025-12-01T19:34:34.047356Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nGPU: Tesla P100-PCIE-16GB\nMemory: 17.06 GB\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## Part 2: Core Classes and Functions\n\nThis section defines all the evaluation functionality.","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass AccuracyResults:\n    \"\"\"Container for accuracy evaluation results.\"\"\"\n    precision_type: str\n    accuracy: float\n    num_correct: int\n    num_total: int\n    per_class_accuracy: Dict[int, float]\n    confusion_matrix: np.ndarray\n    inference_time: float\n    samples_per_second: float\n    batch_size: int\n    num_batches: int\n    \n    def to_dict(self):\n        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n        result = asdict(self)\n        result['confusion_matrix'] = result['confusion_matrix'].tolist()\n        return result\n    \n    def summary(self) -> str:\n        \"\"\"Get a text summary of results.\"\"\"\n        lines = [\n            f\"{'='*60}\",\n            f\"Accuracy Evaluation: {self.precision_type}\",\n            f\"{'='*60}\",\n            f\"Overall Accuracy:    {self.accuracy*100:.2f}% ({self.num_correct}/{self.num_total})\",\n            f\"Inference Time:      {self.inference_time:.3f} seconds\",\n            f\"Throughput:          {self.samples_per_second:.2f} samples/sec\",\n            f\"Batch Configuration: {self.num_batches} batches × {self.batch_size}\",\n            f\"\",\n            f\"Per-Class Accuracy:\",\n        ]\n        for label, acc in self.per_class_accuracy.items():\n            lines.append(f\"  Class {label}: {acc*100:.2f}%\")\n        lines.append(f\"{'='*60}\")\n        return \"\\n\".join(lines)\n\n\nclass AccuracyEvaluator:\n    \"\"\"Complete accuracy evaluation system.\"\"\"\n    \n    def __init__(self, device='cuda'):\n        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')\n        print(f\"AccuracyEvaluator initialized on {self.device}\")\n    \n    def evaluate(\n        self,\n        model: torch.nn.Module,\n        dataset,\n        batch_size: int = 8,\n        precision_type: str = 'FP32',\n        warmup_batches: int = 2\n    ) -> AccuracyResults:\n        \"\"\"Evaluate model accuracy on dataset.\"\"\"\n        model.eval()\n        \n        # Warmup\n        print(f\"Warming up with {warmup_batches} batches...\")\n        with torch.no_grad():\n            for i, batch in enumerate(dataset.get_batch(batch_size)):\n                if i >= warmup_batches:\n                    break\n                _ = model(\n                    input_ids=batch['input_ids'],\n                    attention_mask=batch['attention_mask']\n                )\n        \n        if self.device.type == 'cuda':\n            torch.cuda.synchronize()\n        \n        # Actual evaluation\n        print(f\"Running evaluation on {len(dataset)} samples...\")\n        all_predictions = []\n        all_labels = []\n        num_batches = 0\n        \n        start_time = time.perf_counter()\n        \n        with torch.no_grad():\n            for batch in dataset.get_batch(batch_size):\n                outputs = model(\n                    input_ids=batch['input_ids'],\n                    attention_mask=batch['attention_mask']\n                )\n                \n                logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n                predictions = logits.argmax(dim=-1).cpu().numpy()\n                labels = batch['labels'].cpu().numpy()\n                \n                all_predictions.extend(predictions)\n                all_labels.extend(labels)\n                num_batches += 1\n        \n        if self.device.type == 'cuda':\n            torch.cuda.synchronize()\n        \n        end_time = time.perf_counter()\n        inference_time = end_time - start_time\n        \n        all_predictions = np.array(all_predictions)\n        all_labels = np.array(all_labels)\n        \n        num_correct = (all_predictions == all_labels).sum()\n        num_total = len(all_labels)\n        accuracy = num_correct / num_total\n        \n        per_class_acc = self._compute_per_class_accuracy(all_predictions, all_labels)\n        \n        conf_matrix = confusion_matrix(all_labels, all_predictions)\n        \n        samples_per_second = num_total / inference_time if inference_time > 0 else 0\n        \n        return AccuracyResults(\n            precision_type=precision_type,\n            accuracy=accuracy,\n            num_correct=int(num_correct),\n            num_total=num_total,\n            per_class_accuracy=per_class_acc,\n            confusion_matrix=conf_matrix,\n            inference_time=inference_time,\n            samples_per_second=samples_per_second,\n            batch_size=batch_size,\n            num_batches=num_batches\n        )\n    \n    def _compute_per_class_accuracy(self, predictions: np.ndarray, labels: np.ndarray) -> Dict[int, float]:\n        \"\"\"Compute accuracy per class.\"\"\"\n        unique_labels = np.unique(labels)\n        per_class = {}\n        \n        for label in unique_labels:\n            mask = labels == label\n            class_correct = (predictions[mask] == labels[mask]).sum()\n            class_total = mask.sum()\n            per_class[int(label)] = float(class_correct / class_total) if class_total > 0 else 0.0\n        \n        return per_class\n    \n    def compute_batch_accuracies(self, model, dataset, batch_size: int = 8) -> List[float]:\n        \"\"\"Compute accuracy for each batch individually.\"\"\"\n        model.eval()\n        batch_accuracies = []\n        \n        with torch.no_grad():\n            for batch in dataset.get_batch(batch_size):\n                outputs = model(\n                    input_ids=batch['input_ids'],\n                    attention_mask=batch['attention_mask']\n                )\n                \n                logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n                predictions = logits.argmax(dim=-1)\n                \n                correct = (predictions == batch['labels']).sum().item()\n                total = len(batch['labels'])\n                batch_acc = correct / total\n                batch_accuracies.append(batch_acc)\n        \n        return batch_accuracies\n    \n    def compare_precisions(self, results_list: List[AccuracyResults]) -> Dict:\n        \"\"\"Compare accuracy across different precision levels.\"\"\"\n        comparison = {\n            'precisions': [],\n            'accuracies': [],\n            'throughputs': [],\n            'correct': [],\n            'total': []\n        }\n        \n        for result in results_list:\n            comparison['precisions'].append(result.precision_type)\n            comparison['accuracies'].append(result.accuracy)\n            comparison['throughputs'].append(result.samples_per_second)\n            comparison['correct'].append(result.num_correct)\n            comparison['total'].append(result.num_total)\n        \n        best_idx = np.argmax(comparison['accuracies'])\n        worst_idx = np.argmin(comparison['accuracies'])\n        \n        comparison['best'] = {\n            'precision': comparison['precisions'][best_idx],\n            'accuracy': comparison['accuracies'][best_idx]\n        }\n        comparison['worst'] = {\n            'precision': comparison['precisions'][worst_idx],\n            'accuracy': comparison['accuracies'][worst_idx]\n        }\n        \n        best_acc = comparison['accuracies'][best_idx]\n        comparison['accuracy_drops'] = {\n            prec: (best_acc - acc) * 100\n            for prec, acc in zip(comparison['precisions'], comparison['accuracies'])\n        }\n        \n        return comparison\n    \n    def plot_confusion_matrix(\n        self,\n        results: AccuracyResults,\n        save_path: Optional[str] = None,\n        class_names: Optional[List[str]] = None\n    ):\n        \"\"\"Plot confusion matrix.\"\"\"\n        fig, ax = plt.subplots(figsize=(8, 6))\n        \n        cm = results.confusion_matrix\n        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        \n        sns.heatmap(\n            cm_normalized,\n            annot=True,\n            fmt='.2f',\n            cmap='Blues',\n            xticklabels=class_names or range(len(cm)),\n            yticklabels=class_names or range(len(cm)),\n            ax=ax\n        )\n        \n        ax.set_title(f'Confusion Matrix: {results.precision_type}', fontsize=14, fontweight='bold')\n        ax.set_ylabel('True Label', fontsize=12)\n        ax.set_xlabel('Predicted Label', fontsize=12)\n        \n        plt.tight_layout()\n        \n        if save_path:\n            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n            print(f\"✓ Confusion matrix saved to {save_path}\")\n        \n        plt.show()\n    \n    def save_results(self, results: AccuracyResults, output_path: str):\n        \"\"\"Save results to JSON file.\"\"\"\n        output_path = Path(output_path)\n        output_path.parent.mkdir(parents=True, exist_ok=True)\n        \n        with open(output_path, 'w') as f:\n            json.dump(results.to_dict(), f, indent=2)\n        \n        print(f\"✓ Results saved to {output_path}\")\n    \n    def load_results(self, input_path: str) -> AccuracyResults:\n        \"\"\"Load results from JSON file.\"\"\"\n        with open(input_path, 'r') as f:\n            data = json.load(f)\n        \n        data['confusion_matrix'] = np.array(data['confusion_matrix'])\n        return AccuracyResults(**data)\n\n\ndef compute_accuracy_statistics(accuracies: List[float]) -> Dict[str, float]:\n    \"\"\"Compute statistical summary of accuracies.\"\"\"\n    accuracies_array = np.array(accuracies)\n    \n    return {\n        'mean': float(np.mean(accuracies_array)),\n        'std': float(np.std(accuracies_array)),\n        'min': float(np.min(accuracies_array)),\n        'max': float(np.max(accuracies_array)),\n        'median': float(np.median(accuracies_array)),\n        'ci_95': float(1.96 * np.std(accuracies_array) / np.sqrt(len(accuracies_array)))\n    }\n\n\ndef print_classification_report(predictions: np.ndarray, labels: np.ndarray, class_names: Optional[List[str]] = None):\n    \"\"\"classification report.\"\"\"\n    report = classification_report(labels, predictions, target_names=class_names, digits=4)\n    print(\"\\nClassification Report:\")\n    print(\"=\" * 60)\n    print(report)\n    print(\"=\" * 60)\n\n\nprint(\" Accuracy evaluation classes defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:34.050023Z","iopub.execute_input":"2025-12-01T19:34:34.050693Z","iopub.status.idle":"2025-12-01T19:34:34.082726Z","shell.execute_reply.started":"2025-12-01T19:34:34.050666Z","shell.execute_reply":"2025-12-01T19:34:34.082000Z"}},"outputs":[{"name":"stdout","text":" Accuracy evaluation classes defined\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"class ResultsLogger:\n    \"\"\"Structured logging system for experimental results.\"\"\"\n    \n    def __init__(self, output_dir: str = '/kaggle/working/results'):\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(exist_ok=True, parents=True)\n        self.results = []\n        print(f\"ResultsLogger initialized. Output: {self.output_dir}\")\n    \n    def log_result(\n        self,\n        precision: str,\n        batch_size: int,\n        seq_length: int,\n        accuracy: float,\n        latency: float,\n        avg_power: Optional[float] = None,\n        energy: Optional[float] = None,\n        throughput: Optional[float] = None,\n        num_samples: int = 50,\n        notes: str = \"\"\n    ):\n        \"\"\"Log a single experimental result.\"\"\"\n        if accuracy <= 1.0:\n            accuracy = accuracy * 100.0\n        \n        if throughput is None and latency > 0:\n            throughput = num_samples / latency\n        \n        if energy is None and avg_power is not None and latency > 0:\n            energy = avg_power * latency\n        \n        energy_per_sample = energy / num_samples if energy and num_samples > 0 else None\n        \n        result = {\n            'timestamp': datetime.now().isoformat(),\n            'precision': precision,\n            'batch_size': batch_size,\n            'seq_length': seq_length,\n            'num_samples': num_samples,\n            'accuracy_%': round(accuracy, 2),\n            'latency_s': round(latency, 4),\n            'throughput_samples_s': round(throughput, 2) if throughput else None,\n            'avg_power_w': round(avg_power, 2) if avg_power else None,\n            'energy_j': round(energy, 4) if energy else None,\n            'energy_per_sample_mj': round(energy_per_sample * 1000, 4) if energy_per_sample else None,\n            'notes': notes\n        }\n        \n        self.results.append(result)\n        print(f\"✓ Logged: {precision} | Acc: {accuracy:.2f}% | Latency: {latency:.4f}s\")\n    \n    def get_dataframe(self) -> pd.DataFrame:\n        \"\"\"Get results as pandas DataFrame.\"\"\"\n        return pd.DataFrame(self.results)\n    \n    def save_csv(self, filename: str = 'results.csv'):\n        \"\"\"Save results to CSV file.\"\"\"\n        df = self.get_dataframe()\n        output_path = self.output_dir / filename\n        df.to_csv(output_path, index=False)\n        print(f\"✓ Results saved to {output_path}\")\n        return output_path\n    \n    def save_json(self, filename: str = 'results.json'):\n        \"\"\"Save results to JSON file.\"\"\"\n        output_path = self.output_dir / filename\n        with open(output_path, 'w') as f:\n            json.dump(self.results, f, indent=2)\n        print(f\"✓ Results saved to {output_path}\")\n        return output_path\n    \n    def print_summary(self):\n        \"\"\"Print summary of logged results.\"\"\"\n        if not self.results:\n            print(\"No results logged yet.\")\n            return\n        \n        df = self.get_dataframe()\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\"RESULTS SUMMARY\")\n        print(\"=\"*70)\n        \n        print(f\"\\nTotal experiments: {len(df)}\")\n        print(f\"Precisions: {df['precision'].unique().tolist()}\")\n        print(f\"Batch sizes: {sorted(df['batch_size'].unique().tolist())}\")\n        \n        print(\"\\nAccuracy by Precision:\")\n        print(\"-\"*70)\n        for precision in df['precision'].unique():\n            precision_df = df[df['precision'] == precision]\n            mean_acc = precision_df['accuracy_%'].mean()\n            print(f\"  {precision:6s}: {mean_acc:6.2f}%\")\n        \n        if 'energy_j' in df.columns and df['energy_j'].notna().any():\n            print(\"\\nEnergy by Precision:\")\n            print(\"-\"*70)\n            for precision in df['precision'].unique():\n                precision_df = df[df['precision'] == precision]\n                mean_energy = precision_df['energy_j'].mean()\n                if pd.notna(mean_energy):\n                    print(f\"  {precision:6s}: {mean_energy:8.4f} J\")\n        \n        print(\"=\"*70 + \"\\n\")\n\n\ndef create_results_template(output_path: str = '/kaggle/working/results_template.csv'):\n    \"\"\"Create an empty results template CSV file.\"\"\"\n    template = pd.DataFrame(columns=[\n        'timestamp', 'precision', 'batch_size', 'seq_length', 'num_samples',\n        'accuracy_%', 'latency_s', 'throughput_samples_s', 'avg_power_w',\n        'energy_j', 'energy_per_sample_mj', 'notes'\n    ])\n    \n    template.to_csv(output_path, index=False)\n    print(f\"✓ Results template saved to {output_path}\")\n    return output_path\n\n\nprint(\" Results logging classes defined\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:34.083634Z","iopub.execute_input":"2025-12-01T19:34:34.083896Z","iopub.status.idle":"2025-12-01T19:34:34.102628Z","shell.execute_reply.started":"2025-12-01T19:34:34.083874Z","shell.execute_reply":"2025-12-01T19:34:34.101841Z"}},"outputs":[{"name":"stdout","text":" Results logging classes defined\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# PART 2.5: CREATE PRE-TOKENIZED DATASET (Day 1 Code Inline)\n\nfrom pathlib import Path\nimport torch\nfrom transformers import DistilBertTokenizer\nfrom datasets import load_dataset\nimport json\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"PART 2.5: DATASET PREPARATION\")\nprint(\"=\"*70)\n\ndata_path = Path('/kaggle/working/tokenized_data')\n\nif not data_path.exists():\n    print(\"\\nCreating pre-tokenized dataset...\")\n    print(\"This replicates Day 1 functionality inline\")\n    print(\"-\"*70)\n    \n    data_path.mkdir(parents=True, exist_ok=True)\n    \n    print(\"\\n[1/5] Loading DistilBERT tokenizer...\")\n    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n    print(\"Tokenizer loaded\")\n    \n    print(\"\\n[2/5] Loading SST-2 validation set...\")\n    dataset_raw = load_dataset(\"glue\", \"sst2\", split=\"validation\")\n    print(f\"Loaded {len(dataset_raw)} total examples\")\n    \n    print(\"\\n[3/5] Selecting 50 examples (seed=42)...\")\n    dataset_raw = dataset_raw.shuffle(seed=42).select(range(50))\n    print(\"Selected 50 examples\")\n    \n    print(\"\\n[4/5] Tokenizing with max_length=128...\")\n    texts = [example['sentence'] for example in dataset_raw]\n    labels = [example['label'] for example in dataset_raw]\n    \n    encodings = tokenizer(\n        texts,\n        padding='max_length',\n        truncation=True,\n        max_length=128,\n        return_tensors='pt'\n    )\n    \n    labels_tensor = torch.tensor(labels, dtype=torch.long)\n    print(\"✓ Tokenization complete\")\n    \n    print(\"\\n[5/5] Saving to /kaggle/working/tokenized_data/...\")\n    torch.save(encodings['input_ids'], data_path / 'input_ids.pt')\n    torch.save(encodings['attention_mask'], data_path / 'attention_mask.pt')\n    torch.save(labels_tensor, data_path / 'labels.pt')\n    \n    metadata = {\n        'num_samples': 50,\n        'max_length': 128,\n        'dataset_name': 'sst2',\n        'num_labels': 2,\n        'seed': 42,\n        'tokenizer': 'distilbert-base-uncased',\n    }\n    \n    with open(data_path / 'metadata.json', 'w') as f:\n        json.dump(metadata, f, indent=2)\n    \n    print(\"Files saved\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"DATASET CREATED SUCCESSFULLY!\")\n    print(\"=\"*70)\n    \n    print(\"\\nDataset Summary:\")\n    print(f\"  Location:        {data_path}\")\n    print(f\"  Samples:         50\")\n    print(f\"  Sequence Length: 128 tokens\")\n    print(f\"  Classes:         2 (Negative=0, Positive=1)\")\n    print(f\"  Seed:            42 (reproducible)\")\n    \n    print(\"\\nFiles Created:\")\n    for file in sorted(data_path.glob('*')):\n        size = file.stat().st_size / 1024\n        print(f\"  • {file.name:25s} {size:8.2f} KB\")\n    \n    print(\"\\nFirst 3 Examples:\")\n    for i in range(min(3, len(texts))):\n        print(f\"\\n  Example {i+1}:\")\n        print(f\"    Text:  {texts[i][:60]}...\")\n        print(f\"    Label: {labels[i]} ({'Positive' if labels[i]==1 else 'Negative'})\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"Ready for Part 3: Load Pre-tokenized Dataset\")\n    print(\"=\"*70 + \"\\n\")\n    \nelse:\n    print(\"\\n✓ Dataset already exists at /kaggle/working/tokenized_data/\")\n    print(\"\\nExisting files:\")\n    for file in sorted(data_path.glob('*')):\n        size = file.stat().st_size / 1024\n        print(f\"  • {file.name:25s} {size:8.2f} KB\")\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:34.103515Z","iopub.execute_input":"2025-12-01T19:34:34.103767Z","iopub.status.idle":"2025-12-01T19:34:34.126313Z","shell.execute_reply.started":"2025-12-01T19:34:34.103750Z","shell.execute_reply":"2025-12-01T19:34:34.125639Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nPART 2.5: DATASET PREPARATION\n======================================================================\n\n✓ Dataset already exists at /kaggle/working/tokenized_data/\n\nExisting files:\n  • attention_mask.pt            51.19 KB\n  • input_ids.pt                 51.16 KB\n  • labels.pt                     1.52 KB\n  • metadata.json                 0.14 KB\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Part 3: Load Pre-tokenized Dataset\n\nUse the dataset from Day 1.","metadata":{}},{"cell_type":"code","source":"class PreTokenizedDataset:\n    \"\"\"Load pre-tokenized dataset with zero I/O overhead.\"\"\"\n    \n    def __init__(self, data_dir: str = '/kaggle/working/tokenized_data'):\n        data_path = Path(data_dir)\n\n        print(f\"Loading dataset from {data_dir}...\")\n        self.input_ids = torch.load(data_path / 'input_ids.pt')\n        self.attention_mask = torch.load(data_path / 'attention_mask.pt')\n        self.labels = torch.load(data_path / 'labels.pt')\n        \n        with open(data_path / 'metadata.json', 'r') as f:\n            self.metadata = json.load(f)\n        \n        self.num_samples = len(self.labels)\n        print(f\"Loaded {self.num_samples} samples\")\n    \n    def __len__(self):\n        return self.num_samples\n    \n    def __getitem__(self, idx):\n        return {\n            'input_ids': self.input_ids[idx],\n            'attention_mask': self.attention_mask[idx],\n            'labels': self.labels[idx]\n        }\n    \n    def get_batch(self, batch_size: int = 8):\n        \"\"\"Iterate over batches with zero I/O overhead.\"\"\"\n        for i in range(0, self.num_samples, batch_size):\n            end_idx = min(i + batch_size, self.num_samples)\n            yield {\n                'input_ids': self.input_ids[i:end_idx],\n                'attention_mask': self.attention_mask[i:end_idx],\n                'labels': self.labels[i:end_idx]\n            }\n    \n    def to_device(self, device):\n        \"\"\"Move all tensors to device (GPU) at once.\"\"\"\n        self.input_ids = self.input_ids.to(device)\n        self.attention_mask = self.attention_mask.to(device)\n        self.labels = self.labels.to(device)\n        print(f\"Dataset moved to {device}\")\n        return self\n\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"LOADING PRE-TOKENIZED DATASET\")\nprint(\"=\"*70 + \"\\n\")\n\ndataset = PreTokenizedDataset('/kaggle/working/tokenized_data')\n\nif torch.cuda.is_available():\n    dataset.to_device(device)\n    print(\"Zero I/O overhead during iteration\")\n    print(\"Zero CPU↔GPU transfers during inference\")\nelse:\n    print(\"Dataset on CPU\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"DATASET READY!\")\nprint(\"=\"*70 + \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:34.127162Z","iopub.execute_input":"2025-12-01T19:34:34.127436Z","iopub.status.idle":"2025-12-01T19:34:34.148028Z","shell.execute_reply.started":"2025-12-01T19:34:34.127409Z","shell.execute_reply":"2025-12-01T19:34:34.147338Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nLOADING PRE-TOKENIZED DATASET\n======================================================================\n\nLoading dataset from /kaggle/working/tokenized_data...\nLoaded 50 samples\nDataset moved to cuda\nZero I/O overhead during iteration\nZero CPU↔GPU transfers during inference\n\n======================================================================\nDATASET READY!\n======================================================================\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## Part 4: Evaluate FP32 Baseline\n\n**This works NOW - run immediately!**","metadata":{}},{"cell_type":"code","source":"print(\"Loading FP32 model...\")\nmodel_fp32 = DistilBertForSequenceClassification.from_pretrained(\n    'distilbert-base-uncased-finetuned-sst-2-english',\n    num_labels=2\n).to(device)\n\nprint(f\" Model loaded on {device}\")\nparam_count = sum(p.numel() for p in model_fp32.parameters())\nprint(f\"Parameters: {param_count:,} ({param_count/1e6:.1f}M)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:34.148790Z","iopub.execute_input":"2025-12-01T19:34:34.149581Z","iopub.status.idle":"2025-12-01T19:34:34.475920Z","shell.execute_reply.started":"2025-12-01T19:34:34.149563Z","shell.execute_reply":"2025-12-01T19:34:34.475108Z"}},"outputs":[{"name":"stdout","text":"Loading FP32 model...\n Model loaded on cuda\nParameters: 66,955,010 (67.0M)\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"evaluator = AccuracyEvaluator(device=device)\n\nprint(\"\\nEvaluating FP32...\")\nresults_fp32 = evaluator.evaluate(\n    model=model_fp32,\n    dataset=dataset,\n    batch_size=8,\n    precision_type='FP32',\n    warmup_batches=2\n)\n\nprint(\"\\n\" + results_fp32.summary())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:34.476750Z","iopub.execute_input":"2025-12-01T19:34:34.477271Z","iopub.status.idle":"2025-12-01T19:34:34.987137Z","shell.execute_reply.started":"2025-12-01T19:34:34.477245Z","shell.execute_reply":"2025-12-01T19:34:34.986390Z"}},"outputs":[{"name":"stdout","text":"AccuracyEvaluator initialized on cuda\n\nEvaluating FP32...\nWarming up with 2 batches...\nRunning evaluation on 50 samples...\n\n============================================================\nAccuracy Evaluation: FP32\n============================================================\nOverall Accuracy:    86.00% (43/50)\nInference Time:      0.116 seconds\nThroughput:          431.87 samples/sec\nBatch Configuration: 7 batches × 8\n\nPer-Class Accuracy:\n  Class 0: 85.71%\n  Class 1: 86.21%\n============================================================\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"evaluator.save_results(results_fp32, '/kaggle/working/results/fp32_baseline.json')\n\nevaluator.plot_confusion_matrix(\n    results=results_fp32,\n    save_path='/kaggle/working/results/confusion_matrix_fp32.png',\n    class_names=['Negative', 'Positive']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:34.989935Z","iopub.execute_input":"2025-12-01T19:34:34.990478Z","iopub.status.idle":"2025-12-01T19:34:35.587983Z","shell.execute_reply.started":"2025-12-01T19:34:34.990448Z","shell.execute_reply":"2025-12-01T19:34:35.587357Z"}},"outputs":[{"name":"stdout","text":"✓ Results saved to /kaggle/working/results/fp32_baseline.json\n✓ Confusion matrix saved to /kaggle/working/results/confusion_matrix_fp32.png\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":22},{"cell_type":"markdown","source":"## Part 5: Batch-Level Analysis","metadata":{}},{"cell_type":"code","source":"print(\"Computing batch-level accuracies...\")\nbatch_accuracies = evaluator.compute_batch_accuracies(\n    model=model_fp32,\n    dataset=dataset,\n    batch_size=8\n)\n\nprint(\"\\nPer-Batch Accuracies:\")\nprint(\"=\"*60)\nfor i, acc in enumerate(batch_accuracies, 1):\n    print(f\"Batch {i}: {acc*100:.2f}%\")\n\nstats = compute_accuracy_statistics(batch_accuracies)\nprint(\"\\nBatch Accuracy Statistics:\")\nprint(\"=\"*60)\nprint(f\"Mean:   {stats['mean']*100:.2f}%\")\nprint(f\"Std:    {stats['std']*100:.2f}%\")\nprint(f\"Min:    {stats['min']*100:.2f}%\")\nprint(f\"Max:    {stats['max']*100:.2f}%\")\nprint(f\"Median: {stats['median']*100:.2f}%\")\nprint(f\"95% CI: ±{stats['ci_95']*100:.2f}%\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:35.588566Z","iopub.execute_input":"2025-12-01T19:34:35.588828Z","iopub.status.idle":"2025-12-01T19:34:35.748528Z","shell.execute_reply.started":"2025-12-01T19:34:35.588806Z","shell.execute_reply":"2025-12-01T19:34:35.747748Z"}},"outputs":[{"name":"stdout","text":"Computing batch-level accuracies...\n\nPer-Batch Accuracies:\n============================================================\nBatch 1: 87.50%\nBatch 2: 87.50%\nBatch 3: 75.00%\nBatch 4: 87.50%\nBatch 5: 87.50%\nBatch 6: 87.50%\nBatch 7: 100.00%\n\nBatch Accuracy Statistics:\n============================================================\nMean:   87.50%\nStd:    6.68%\nMin:    75.00%\nMax:    100.00%\nMedian: 87.50%\n95% CI: ±4.95%\n============================================================\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## Part 6: Detailed Classification Report","metadata":{}},{"cell_type":"code","source":"all_preds = []\nall_labels = []\n\nmodel_fp32.eval()\nwith torch.no_grad():\n    for batch in dataset.get_batch(8):\n        outputs = model_fp32(\n            input_ids=batch['input_ids'],\n            attention_mask=batch['attention_mask']\n        )\n        preds = outputs.logits.argmax(dim=-1).cpu().numpy()\n        labels = batch['labels'].cpu().numpy()\n        all_preds.extend(preds)\n        all_labels.extend(labels)\n\nprint_classification_report(\n    predictions=np.array(all_preds),\n    labels=np.array(all_labels),\n    class_names=['Negative', 'Positive']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:35.749277Z","iopub.execute_input":"2025-12-01T19:34:35.749528Z","iopub.status.idle":"2025-12-01T19:34:36.650532Z","shell.execute_reply.started":"2025-12-01T19:34:35.749510Z","shell.execute_reply":"2025-12-01T19:34:36.649721Z"}},"outputs":[{"name":"stdout","text":"\nClassification Report:\n============================================================\n              precision    recall  f1-score   support\n\n    Negative     0.8182    0.8571    0.8372        21\n    Positive     0.8929    0.8621    0.8772        29\n\n    accuracy                         0.8600        50\n   macro avg     0.8555    0.8596    0.8572        50\nweighted avg     0.8615    0.8600    0.8604        50\n\n============================================================\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## Part 7: Log Results to CSV","metadata":{}},{"cell_type":"code","source":"logger = ResultsLogger(output_dir='/kaggle/working/results')\n\nlogger.log_result(\n    precision='FP32',\n    batch_size=8,\n    seq_length=128,\n    accuracy=results_fp32.accuracy,\n    latency=results_fp32.inference_time,\n    throughput=results_fp32.samples_per_second,\n    num_samples=results_fp32.num_total,\n    notes='Baseline - fine-tuned DistilBERT'\n)\n\nlogger.log_result(\n    precision='FP16',\n    batch_size=8,\n    seq_length=128,\n    accuracy=0.0,\n    latency=0.0,\n    num_samples=50,\n    notes='Waiting for Thomas - FP16 model'\n)\n\nlogger.log_result(\n    precision='INT8',\n    batch_size=8,\n    seq_length=128,\n    accuracy=0.0,\n    latency=0.0,\n    num_samples=50,\n    notes='Waiting for Thomas - INT8 model'\n)\n\nlogger.print_summary()\n\nlogger.save_csv('results.csv')\nlogger.save_json('results.json')\n\ncreate_results_template('/kaggle/working/results_template.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:36.651301Z","iopub.execute_input":"2025-12-01T19:34:36.651614Z","iopub.status.idle":"2025-12-01T19:34:36.683287Z","shell.execute_reply.started":"2025-12-01T19:34:36.651586Z","shell.execute_reply":"2025-12-01T19:34:36.682555Z"}},"outputs":[{"name":"stdout","text":"ResultsLogger initialized. Output: /kaggle/working/results\n✓ Logged: FP32 | Acc: 86.00% | Latency: 0.1158s\n✓ Logged: FP16 | Acc: 0.00% | Latency: 0.0000s\n✓ Logged: INT8 | Acc: 0.00% | Latency: 0.0000s\n\n======================================================================\nRESULTS SUMMARY\n======================================================================\n\nTotal experiments: 3\nPrecisions: ['FP32', 'FP16', 'INT8']\nBatch sizes: [8]\n\nAccuracy by Precision:\n----------------------------------------------------------------------\n  FP32  :  86.00%\n  FP16  :   0.00%\n  INT8  :   0.00%\n======================================================================\n\n✓ Results saved to /kaggle/working/results/results.csv\n✓ Results saved to /kaggle/working/results/results.json\n✓ Results template saved to /kaggle/working/results_template.csv\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/results_template.csv'"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"## Part 8: View Results Table","metadata":{}},{"cell_type":"code","source":"df_results = logger.get_dataframe()\nprint(\"\\nCurrent Results Table:\")\nprint(\"=\"*100)\ndisplay(df_results)\nprint(\"=\"*100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:36.684171Z","iopub.execute_input":"2025-12-01T19:34:36.684408Z","iopub.status.idle":"2025-12-01T19:34:36.715125Z","shell.execute_reply.started":"2025-12-01T19:34:36.684390Z","shell.execute_reply":"2025-12-01T19:34:36.714362Z"}},"outputs":[{"name":"stdout","text":"\nCurrent Results Table:\n====================================================================================================\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                    timestamp precision  batch_size  seq_length  num_samples  \\\n0  2025-12-01T19:34:36.654188      FP32           8         128           50   \n1  2025-12-01T19:34:36.654300      FP16           8         128           50   \n2  2025-12-01T19:34:36.654394      INT8           8         128           50   \n\n   accuracy_%  latency_s  throughput_samples_s avg_power_w energy_j  \\\n0        86.0     0.1158                431.87        None     None   \n1         0.0     0.0000                   NaN        None     None   \n2         0.0     0.0000                   NaN        None     None   \n\n  energy_per_sample_mj                             notes  \n0                 None  Baseline - fine-tuned DistilBERT  \n1                 None   Waiting for Thomas - FP16 model  \n2                 None   Waiting for Thomas - INT8 model  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timestamp</th>\n      <th>precision</th>\n      <th>batch_size</th>\n      <th>seq_length</th>\n      <th>num_samples</th>\n      <th>accuracy_%</th>\n      <th>latency_s</th>\n      <th>throughput_samples_s</th>\n      <th>avg_power_w</th>\n      <th>energy_j</th>\n      <th>energy_per_sample_mj</th>\n      <th>notes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2025-12-01T19:34:36.654188</td>\n      <td>FP32</td>\n      <td>8</td>\n      <td>128</td>\n      <td>50</td>\n      <td>86.0</td>\n      <td>0.1158</td>\n      <td>431.87</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Baseline - fine-tuned DistilBERT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2025-12-01T19:34:36.654300</td>\n      <td>FP16</td>\n      <td>8</td>\n      <td>128</td>\n      <td>50</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Waiting for Thomas - FP16 model</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2025-12-01T19:34:36.654394</td>\n      <td>INT8</td>\n      <td>8</td>\n      <td>128</td>\n      <td>50</td>\n      <td>0.0</td>\n      <td>0.0000</td>\n      <td>NaN</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Waiting for Thomas - INT8 model</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"====================================================================================================\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"## Part 9: Placeholder for FP16/INT8 Evaluation\n\n**Ready when Thomas provides models - just uncomment and run!**","metadata":{}},{"cell_type":"code","source":"# UNCOMMENT WHEN THOMAS PROVIDES FP16 MODEL\n\n# # Load FP16 model (Thomas will provide)\n# model_fp16 = load_fp16_model()  # Replace with actual loading code\n# model_fp16 = model_fp16.to(device)\n\n# # Evaluate FP16\n# results_fp16 = evaluator.evaluate(\n#     model=model_fp16,\n#     dataset=dataset,\n#     batch_size=8,\n#     precision_type='FP16'\n# )\n\n# # Print and save\n# print(results_fp16.summary())\n# evaluator.save_results(results_fp16, '/kaggle/working/results/fp16_results.json')\n# evaluator.plot_confusion_matrix(results_fp16, save_path='/kaggle/working/results/confusion_fp16.png')\n\n# # Log to CSV\n# logger.log_result(\n#     precision='FP16',\n#     batch_size=8,\n#     seq_length=128,\n#     accuracy=results_fp16.accuracy,\n#     latency=results_fp16.inference_time,\n#     throughput=results_fp16.samples_per_second,\n#     num_samples=results_fp16.num_total\n# )\n\nprint(\"FP16 evaluation code ready (currently commented out)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:36.715892Z","iopub.execute_input":"2025-12-01T19:34:36.716147Z","iopub.status.idle":"2025-12-01T19:34:36.720909Z","shell.execute_reply.started":"2025-12-01T19:34:36.716119Z","shell.execute_reply":"2025-12-01T19:34:36.719982Z"}},"outputs":[{"name":"stdout","text":"FP16 evaluation code ready (currently commented out)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# UNCOMMENT WHEN THOMAS PROVIDES INT8 MODEL\n\n# # Load INT8 model (Thomas will provide)\n# model_int8 = load_int8_model()  # Replace with actual loading code\n# model_int8 = model_int8.to(device)\n\n# # Evaluate INT8\n# results_int8 = evaluator.evaluate(\n#     model=model_int8,\n#     dataset=dataset,\n#     batch_size=8,\n#     precision_type='INT8'\n# )\n\n# # Print and save\n# print(results_int8.summary())\n# evaluator.save_results(results_int8, '/kaggle/working/results/int8_results.json')\n# evaluator.plot_confusion_matrix(results_int8, save_path='/kaggle/working/results/confusion_int8.png')\n\n# # Log to CSV\n# logger.log_result(\n#     precision='INT8',\n#     batch_size=8,\n#     seq_length=128,\n#     accuracy=results_int8.accuracy,\n#     latency=results_int8.inference_time,\n#     throughput=results_int8.samples_per_second,\n#     num_samples=results_int8.num_total\n# )\n\nprint(\"INT8 evaluation code ready (currently commented out)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:36.721770Z","iopub.execute_input":"2025-12-01T19:34:36.722012Z","iopub.status.idle":"2025-12-01T19:34:36.738101Z","shell.execute_reply.started":"2025-12-01T19:34:36.721991Z","shell.execute_reply":"2025-12-01T19:34:36.737373Z"}},"outputs":[{"name":"stdout","text":"INT8 evaluation code ready (currently commented out)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## Part 10: Compare All Precisions\n\n**Uncomment when all models evaluated**","metadata":{}},{"cell_type":"code","source":"# UNCOMMENT WHEN ALL MODELS EVALUATED\n\n# # Compare all precisions\n# comparison = evaluator.compare_precisions([\n#     results_fp32,\n#     results_fp16,\n#     results_int8\n# ])\n\n# print(\"\\nComparison Across Precisions:\")\n# print(\"=\"*70)\n# for i, prec in enumerate(comparison['precisions']):\n#     print(f\"\\n{prec}:\")\n#     print(f\"  Accuracy:     {comparison['accuracies'][i]*100:.2f}%\")\n#     print(f\"  Throughput:   {comparison['throughputs'][i]:.2f} samples/s\")\n#     print(f\"  Accuracy Drop: {comparison['accuracy_drops'][prec]:.2f}%\")\n\n# print(f\"\\nBest: {comparison['best']['precision']} ({comparison['best']['accuracy']*100:.2f}%)\")\n# print(f\"Worst: {comparison['worst']['precision']} ({comparison['worst']['accuracy']*100:.2f}%)\")\n# print(\"=\"*70)\n\nprint(\"Comparison code ready (currently commented out)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:36.739272Z","iopub.execute_input":"2025-12-01T19:34:36.739539Z","iopub.status.idle":"2025-12-01T19:34:36.752199Z","shell.execute_reply.started":"2025-12-01T19:34:36.739515Z","shell.execute_reply":"2025-12-01T19:34:36.751423Z"}},"outputs":[{"name":"stdout","text":"Comparison code ready (currently commented out)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## Part 11: Summary and Files Generated","metadata":{}},{"cell_type":"code","source":"# List all generated files\nprint(\"\\n\" + \"=\"*70)\nprint(\"FILES GENERATED\")\nprint(\"=\"*70)\n\nresults_dir = Path('/kaggle/working/results')\nif results_dir.exists():\n    files = list(results_dir.glob('*'))\n    for file in sorted(files):\n        size = file.stat().st_size / 1024  # KB\n        print(f\"  {file.name:40s} {size:8.2f} KB\")\nelse:\n    print(\"  (No results directory yet)\")\n\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:36.752957Z","iopub.execute_input":"2025-12-01T19:34:36.753225Z","iopub.status.idle":"2025-12-01T19:34:36.771602Z","shell.execute_reply.started":"2025-12-01T19:34:36.753204Z","shell.execute_reply":"2025-12-01T19:34:36.770904Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nFILES GENERATED\n======================================================================\n  confusion_matrix_fp32.png                   93.78 KB\n  fp32_baseline.json                           0.38 KB\n  results.csv                                  0.40 KB\n  results.json                                 1.05 KB\n======================================================================\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# Final summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"DAY 2 CHECKPOINT COMPLETE\")\nprint(\"=\"*70)\n\nprint(\"\\n✓ What You Accomplished:\")\nprint(\"  - FP32 baseline evaluated\")\nprint(f\"  - Accuracy: {results_fp32.accuracy*100:.2f}%\")\nprint(\"  - Confusion matrix generated\")\nprint(\"  - Per-class accuracy computed\")\nprint(\"  - Batch-level statistics analyzed\")\nprint(\"  - Results logged to CSV\")\nprint(\"  - Code ready for FP16/INT8\")\n\nprint(\"\\n Waiting For:\")\nprint(\"  - Thomas: FP16 and INT8 models (Day 3)\")\nprint(\"  - Krishna: Energy measurements (Day 4-5)\")\n\nprint(\"\\nKey Files:\")\nprint(\"  - results.csv - Results table (accuracy filled)\")\nprint(\"  - fp32_baseline.json - FP32 detailed results\")\nprint(\"  - confusion_matrix_fp32.png - Visualization\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"Ready for Day 3!\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:34:36.772389Z","iopub.execute_input":"2025-12-01T19:34:36.772596Z","iopub.status.idle":"2025-12-01T19:34:36.785830Z","shell.execute_reply.started":"2025-12-01T19:34:36.772572Z","shell.execute_reply":"2025-12-01T19:34:36.785096Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nDAY 2 CHECKPOINT COMPLETE\n======================================================================\n\n✓ What You Accomplished:\n  - FP32 baseline evaluated\n  - Accuracy: 86.00%\n  - Confusion matrix generated\n  - Per-class accuracy computed\n  - Batch-level statistics analyzed\n  - Results logged to CSV\n  - Code ready for FP16/INT8\n\n Waiting For:\n  - Thomas: FP16 and INT8 models (Day 3)\n  - Krishna: Energy measurements (Day 4-5)\n\nKey Files:\n  - results.csv - Results table (accuracy filled)\n  - fp32_baseline.json - FP32 detailed results\n  - confusion_matrix_fp32.png - Visualization\n\n======================================================================\nReady for Day 3!\n======================================================================\n","output_type":"stream"}],"execution_count":31}]}