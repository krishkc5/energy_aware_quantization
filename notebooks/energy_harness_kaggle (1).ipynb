{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Measurement Harness - Kaggle Edition\n",
    "## For Krishna: Complete Energy + Latency Measurement System\n",
    "\n",
    "**Purpose:** Measure GPU power, energy, and latency for FP32, FP16, INT8 models\n",
    "\n",
    "**Architecture:** 10-layer design from specifications\n",
    "- Zero I/O during measurement\n",
    "- Multi-trial support (5 trials for statistical confidence)\n",
    "- PowerLogger for nvidia-smi\n",
    "- CSV/JSON output\n",
    "\n",
    "**Integration:** Uses Taara's pre-tokenized dataset, merges with accuracy results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install -q transformers datasets\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "print(\"‚úì Imports complete\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 0: Config & Experiment Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@dataclass\nclass ExperimentConfig:\n    \"\"\"Configuration for energy measurement experiments.\"\"\"\n    model_name: str = \"distilbert-base-uncased-finetuned-sst-2-english\"\n    precision: str = \"fp32\"\n    \n    # ADJUSTED PARAMETERS for better sample usage\n    batch_size: int = 16  # Reduced from 32 to extend data coverage\n    seq_len: int = 128\n    num_loops: int = 500  # Reduced from 1000 to 500\n    warmup_loops: int = 50  # Reduced from 100 to 50\n    \n    # LOCAL PATH (for running locally)\n    # Current dataset has 100 samples\n    dataset_path: str = r\"c:\\Users\\taara\\UPENN JR FALL\\ESE 5390\\energy_aware_quantization\\datasets\\tokenized_data_large\"\n    \n    # KAGGLE PATH (uncomment when running on Kaggle)\n    # dataset_path: str = \"/kaggle/working/tokenized_data\"\n    \n    device: str = \"cuda\"\n    num_trials: int = 5\n    poll_interval_ms: int = 100\n\n# Create default config\nconfig = ExperimentConfig()\n\nprint(\"Configuration:\")\nprint(\"-\" * 60)\nfor key, value in asdict(config).items():\n    print(f\"  {key:20s}: {value}\")\nprint(\"-\" * 60)\n\n# Calculate sample statistics\ntotal_samples_needed = config.num_loops * config.batch_size\nprint(f\"\\nüìä Sample Usage Analysis:\")\nprint(f\"  Total inferences per trial: {total_samples_needed:,}\")\nprint(f\"  Dataset has ~100 samples\")\nprint(f\"  Each sample reused: ~{total_samples_needed // 100} times\")\nprint(f\"\\n  ‚ö†Ô∏è  NOTE: For more unique samples, run create_large_dataset.py\")\nprint(f\"  ‚úì  This generates 500-872 samples to reduce reuse to ~16-32x\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 1: Dataset & Model Loading (Zero I/O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def load_pre_tokenized_dataset(dataset_path: str, device: str):\n    \"\"\"Load pre-tokenized dataset - ALL data to GPU at once.\"\"\"\n    data_path = Path(dataset_path)\n    \n    print(f\"\\nLoading dataset from {dataset_path}...\")\n    \n    # Check if files exist\n    if not (data_path / 'input_ids.pt').exists():\n        raise FileNotFoundError(\n            f\"Dataset not found at {dataset_path}\\n\"\n            f\"Looking for: {data_path / 'input_ids.pt'}\\n\"\n            f\"Please ensure:\\n\"\n            f\"  1. You've created the tokenized dataset\\n\"\n            f\"  2. The path is correct (use local path for local runs, Kaggle path for Kaggle)\\n\"\n            f\"  3. Files exist: input_ids.pt, attention_mask.pt, labels.pt\"\n        )\n    \n    input_ids = torch.load(data_path / 'input_ids.pt').to(device)\n    attention_mask = torch.load(data_path / 'attention_mask.pt').to(device)\n    labels = torch.load(data_path / 'labels.pt').to(device)\n    \n    print(f\"‚úì Loaded {len(labels)} samples to {device}\")\n    print(f\"  - Input shape: {input_ids.shape}\")\n    print(f\"  - Zero I/O during measurement ‚úì\")\n    \n    return input_ids, attention_mask, labels\n\n\ndef batched_iterator(input_ids, attention_mask, batch_size: int):\n    \"\"\"Infinite batch iterator with wraparound (zero I/O).\"\"\"\n    N = input_ids.size(0)\n    idx = 0\n    \n    while True:\n        end_idx = idx + batch_size\n        \n        if end_idx <= N:\n            yield input_ids[idx:end_idx], attention_mask[idx:end_idx]\n            idx = end_idx\n        else:\n            # Wraparound: reuse samples from beginning\n            idx = 0\n\n\ndef load_model(precision: str, model_name: str, device: str):\n    \"\"\"Load model with specified precision.\"\"\"\n    print(f\"\\nLoading {precision.upper()} model...\")\n    \n    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n    model.to(device)\n    model.eval()\n    \n    if precision == \"fp16\":\n        model = model.half()\n        print(\"‚úì Converted to FP16\")\n    elif precision == \"int8\":\n        print(\"‚ö† INT8 quantization not implemented yet\")\n        print(\"  Using FP32 as placeholder (Thomas will implement)\")\n    \n    print(f\"‚úì Model loaded on {device}\")\n    param_count = sum(p.numel() for p in model.parameters())\n    print(f\"  - Parameters: {param_count:,} ({param_count/1e6:.1f}M)\")\n    \n    return model\n\n\nprint(\"‚úì Data/model loading functions defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 2: Warmup Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup(model, batch_iter, num_iters: int):\n",
    "    \"\"\"Warmup to stabilize GPU clocks.\"\"\"\n",
    "    print(f\"\\nWarming up with {num_iters} iterations...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_iters):\n",
    "            input_ids, attention_mask = next(batch_iter)\n",
    "            _ = model(input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"  Warmup: {i+1}/{num_iters}\")\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    print(\"‚úì Warmup complete - GPU stabilized\")\n",
    "\n",
    "\n",
    "print(\"‚úì Warmup function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 3: Timed Inference Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_loop(model, batch_iter, num_loops: int) -> float:\n",
    "    \"\"\"Timed inference loop for latency measurement.\"\"\"\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_loops):\n",
    "            input_ids, attention_mask = next(batch_iter)\n",
    "            _ = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    end = time.perf_counter()\n",
    "    \n",
    "    return end - start\n",
    "\n",
    "\n",
    "print(\"‚úì Inference loop function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 4: Power Logger (CRITICAL - Krishna Must Test This)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerLogger:\n",
    "    \"\"\"GPU power monitoring using nvidia-smi.\"\"\"\n",
    "    \n",
    "    def __init__(self, gpu_id: int = 0, poll_interval_ms: int = 100):\n",
    "        self.gpu_id = gpu_id\n",
    "        self.poll_interval_ms = poll_interval_ms\n",
    "        self.proc = None\n",
    "        self.samples = []\n",
    "        self.thread = None\n",
    "        self.stop_flag = False\n",
    "        \n",
    "    def start(self):\n",
    "        \"\"\"Start power monitoring.\"\"\"\n",
    "        print(f\"\\n[PowerLogger] Starting (poll: {self.poll_interval_ms}ms)...\")\n",
    "        \n",
    "        # CRITICAL: Test which command works on Kaggle\n",
    "        # Option 1: Millisecond interval (if supported)\n",
    "        cmd = [\n",
    "            'nvidia-smi',\n",
    "            '--query-gpu=power.draw',\n",
    "            '--format=csv,noheader,nounits',\n",
    "            f'--id={self.gpu_id}',\n",
    "            '-lms', str(self.poll_interval_ms)\n",
    "        ]\n",
    "        \n",
    "        # Option 2: Second interval (if -lms doesn't work)\n",
    "        # cmd = [\n",
    "        #     'nvidia-smi',\n",
    "        #     '--query-gpu=power.draw',\n",
    "        #     '--format=csv,noheader,nounits',\n",
    "        #     f'--id={self.gpu_id}',\n",
    "        #     '-l', '1'  # 1 second interval\n",
    "        # ]\n",
    "        \n",
    "        try:\n",
    "            self.proc = subprocess.Popen(\n",
    "                cmd,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE,\n",
    "                universal_newlines=True,\n",
    "                bufsize=1\n",
    "            )\n",
    "            \n",
    "            self.stop_flag = False\n",
    "            self.thread = threading.Thread(target=self._collect_samples)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "            \n",
    "            print(\"[PowerLogger] ‚úì Started\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[PowerLogger] ‚úó Failed: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _collect_samples(self):\n",
    "        \"\"\"Collect power samples in background.\"\"\"\n",
    "        while not self.stop_flag and self.proc and self.proc.poll() is None:\n",
    "            line = self.proc.stdout.readline()\n",
    "            if line:\n",
    "                try:\n",
    "                    power = float(line.strip())\n",
    "                    self.samples.append(power)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "    \n",
    "    def stop(self) -> List[float]:\n",
    "        \"\"\"Stop and return samples.\"\"\"\n",
    "        print(f\"[PowerLogger] Stopping...\")\n",
    "        \n",
    "        self.stop_flag = True\n",
    "        \n",
    "        if self.proc:\n",
    "            self.proc.terminate()\n",
    "            try:\n",
    "                self.proc.wait(timeout=2)\n",
    "            except subprocess.TimeoutExpired:\n",
    "                self.proc.kill()\n",
    "        \n",
    "        if self.thread:\n",
    "            self.thread.join(timeout=2)\n",
    "        \n",
    "        print(f\"[PowerLogger] ‚úì Stopped - {len(self.samples)} samples\")\n",
    "        \n",
    "        if len(self.samples) == 0:\n",
    "            print(\"[PowerLogger] ‚ö† WARNING: No samples collected!\")\n",
    "            print(\"  Krishna: Test nvidia-smi command manually\")\n",
    "        \n",
    "        return self.samples.copy()\n",
    "\n",
    "\n",
    "print(\"‚úì PowerLogger class defined\")\n",
    "print(\"‚ö† Krishna: TEST THIS FIRST before running experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST POWERLOGGER FIRST! (Run this cell before anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL TEST - Run this first!\n",
    "print(\"Testing PowerLogger...\")\n",
    "print(\"This will run for 5 seconds\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "logger = PowerLogger(gpu_id=0, poll_interval_ms=100)\n",
    "logger.start()\n",
    "time.sleep(5)\n",
    "samples = logger.stop()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Samples collected: {len(samples)}\")\n",
    "\n",
    "if len(samples) > 0:\n",
    "    print(f\"  Sample values: {samples[:5]}\")\n",
    "    print(f\"  Mean power: {np.mean(samples):.2f} W\")\n",
    "    print(\"\\n‚úì PowerLogger WORKS! You can proceed.\")\n",
    "else:\n",
    "    print(\"\\n‚úó PowerLogger returned 0 samples!\")\n",
    "    print(\"\\nDebugging steps:\")\n",
    "    print(\"1. Test nvidia-smi manually:\")\n",
    "    print(\"   !timeout 10 nvidia-smi --query-gpu=power.draw --format=csv,noheader,nounits -l 1\")\n",
    "    print(\"2. Try different interval formats:\")\n",
    "    print(\"   -lms 100  (milliseconds)\")\n",
    "    print(\"   -l 1      (seconds)\")\n",
    "    print(\"3. Update PowerLogger.start() command based on what works\")\n",
    "    print(\"\\n‚ö† DO NOT PROCEED until this works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 5: Energy & Latency Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy_metrics(power_samples: List[float], total_time: float, num_inferences: int) -> Dict:\n",
    "    \"\"\"Compute energy and latency metrics.\"\"\"\n",
    "    if len(power_samples) == 0:\n",
    "        raise ValueError(\"No power samples - cannot compute energy\")\n",
    "    \n",
    "    avg_power = float(np.mean(power_samples))\n",
    "    std_power = float(np.std(power_samples))\n",
    "    energy_total = avg_power * total_time\n",
    "    energy_per_inference = energy_total / num_inferences\n",
    "    latency_per_sample = total_time / num_inferences\n",
    "    throughput = num_inferences / total_time\n",
    "    \n",
    "    return {\n",
    "        \"avg_power_w\": avg_power,\n",
    "        \"std_power_w\": std_power,\n",
    "        \"energy_total_j\": energy_total,\n",
    "        \"energy_per_inference_j\": energy_per_inference,\n",
    "        \"energy_per_inference_mj\": energy_per_inference * 1000,\n",
    "        \"latency_per_sample_s\": latency_per_sample,\n",
    "        \"latency_per_sample_ms\": latency_per_sample * 1000,\n",
    "        \"throughput_samples_s\": throughput,\n",
    "        \"total_time_s\": total_time,\n",
    "        \"num_inferences\": num_inferences,\n",
    "        \"num_power_samples\": len(power_samples),\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úì Energy computation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 6: Measure with Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def measure_with_power(model, batch_iter, num_loops: int, logger: PowerLogger):\n    \"\"\"Run inference with power monitoring.\"\"\"\n    logger.start()\n    time.sleep(0.5)  # Let logger stabilize\n    \n    total_time = run_inference_loop(model, batch_iter, num_loops)\n    \n    power_samples = logger.stop()\n    \n    return total_time, power_samples\n\n\nprint(\"‚úì Measurement function defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Layer 6.5: Per-Layer Energy Measurement\n\nThis section enables measuring energy consumption for each layer of DistilBERT individually."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments_for_precision(config, precision: str, num_trials: int = 5):\n",
    "    \"\"\"Run multiple trials for one precision.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"RUNNING EXPERIMENTS: {precision.upper()}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load dataset once\n",
    "    input_ids, attention_mask, labels = load_pre_tokenized_dataset(\n",
    "        config.dataset_path, config.device\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        print(f\"\\n{'‚îÄ'*70}\")\n",
    "        print(f\"Trial {trial + 1}/{num_trials}\")\n",
    "        print(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        # Create batch iterator\n",
    "        batch_iter = batched_iterator(input_ids, attention_mask, config.batch_size)\n",
    "        \n",
    "        # Load model\n",
    "        model = load_model(precision, config.model_name, config.device)\n",
    "        \n",
    "        # Warmup\n",
    "        warmup(model, batch_iter, config.warmup_loops)\n",
    "        \n",
    "        # New iterator for measurement\n",
    "        batch_iter = batched_iterator(input_ids, attention_mask, config.batch_size)\n",
    "        \n",
    "        # Measure\n",
    "        print(f\"\\nRunning {config.num_loops} measurement iterations...\")\n",
    "        logger = PowerLogger(gpu_id=0, poll_interval_ms=config.poll_interval_ms)\n",
    "        \n",
    "        try:\n",
    "            total_time, power_samples = measure_with_power(\n",
    "                model, batch_iter, config.num_loops, logger\n",
    "            )\n",
    "            \n",
    "            num_inferences = config.num_loops * config.batch_size\n",
    "            metrics = compute_energy_metrics(power_samples, total_time, num_inferences)\n",
    "            \n",
    "            metrics[\"precision\"] = precision\n",
    "            metrics[\"trial\"] = trial\n",
    "            metrics[\"batch_size\"] = config.batch_size\n",
    "            metrics[\"seq_len\"] = config.seq_len\n",
    "            \n",
    "            results.append(metrics)\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"\\n{'‚îÄ'*70}\")\n",
    "            print(f\"Trial {trial + 1} Results:\")\n",
    "            print(f\"{'‚îÄ'*70}\")\n",
    "            print(f\"  Latency:    {metrics['latency_per_sample_ms']:.3f} ms\")\n",
    "            print(f\"  Throughput: {metrics['throughput_samples_s']:.2f} samples/s\")\n",
    "            print(f\"  Avg Power:  {metrics['avg_power_w']:.2f} W\")\n",
    "            print(f\"  Energy:     {metrics['energy_per_inference_mj']:.3f} mJ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚úó Trial {trial + 1} failed: {e}\")\n",
    "            continue\n",
    "        \n",
    "        finally:\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úì Multi-trial runner defined\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "class LayerEnergyProfiler:\n    \"\"\"\n    Measures energy consumption per layer in a DistilBERT model.\n    \n    DistilBERT Architecture:\n    - Embeddings (word + position)\n    - 6 Transformer blocks (each with attention + FFN)\n    - Pre-classifier\n    - Classifier head\n    \"\"\"\n    \n    def __init__(self, model, device='cuda'):\n        self.model = model\n        self.device = device\n        self.layer_names = []\n        self.layer_modules = []\n        \n        # Register DistilBERT layers\n        self._register_layers()\n        \n    def _register_layers(self):\n        \"\"\"Register all major layers for profiling.\"\"\"\n        # Embedding layer\n        if hasattr(self.model, 'distilbert'):\n            self.layer_names.append('embeddings')\n            self.layer_modules.append(self.model.distilbert.embeddings)\n            \n            # Transformer blocks\n            for i, layer in enumerate(self.model.distilbert.transformer.layer):\n                self.layer_names.append(f'transformer_block_{i}')\n                self.layer_modules.append(layer)\n        \n        # Classification head\n        if hasattr(self.model, 'pre_classifier'):\n            self.layer_names.append('pre_classifier')\n            self.layer_modules.append(self.model.pre_classifier)\n        \n        if hasattr(self.model, 'classifier'):\n            self.layer_names.append('classifier')\n            self.layer_modules.append(self.model.classifier)\n        \n        print(f\"‚úì Registered {len(self.layer_names)} layers for profiling\")\n        for name in self.layer_names:\n            print(f\"  - {name}\")\n    \n    def run_layer_inference(self, input_ids, attention_mask, layer_idx: int) -> float:\n        \"\"\"\n        Run inference through a specific layer multiple times and measure time.\n        \n        Returns: Total time in seconds\n        \"\"\"\n        torch.cuda.synchronize()\n        start = time.perf_counter()\n        \n        with torch.no_grad():\n            # Run through model up to and including this layer\n            if layer_idx == 0:\n                # Embeddings only\n                _ = self.model.distilbert.embeddings(input_ids)\n            elif layer_idx <= 6:\n                # Embeddings + transformer blocks up to layer_idx\n                hidden_states = self.model.distilbert.embeddings(input_ids)\n                for i in range(layer_idx):\n                    hidden_states = self.model.distilbert.transformer.layer[i](\n                        hidden_states, attention_mask\n                    )[0]\n            else:\n                # Full forward pass\n                _ = self.model(input_ids, attention_mask=attention_mask)\n        \n        torch.cuda.synchronize()\n        end = time.perf_counter()\n        \n        return end - start\n    \n    def measure_layer_energy(\n        self, \n        batch_iter, \n        layer_idx: int,\n        num_loops: int = 100,\n        logger: PowerLogger = None\n    ) -> Dict:\n        \"\"\"\n        Measure energy for a specific layer.\n        \n        Args:\n            batch_iter: Iterator providing batches\n            layer_idx: Index of layer to measure\n            num_loops: Number of inference loops\n            logger: PowerLogger instance\n            \n        Returns:\n            Dict with energy metrics for this layer\n        \"\"\"\n        layer_name = self.layer_names[layer_idx]\n        print(f\"\\n  Measuring layer: {layer_name}\")\n        \n        if logger is None:\n            logger = PowerLogger(gpu_id=0, poll_interval_ms=100)\n        \n        # Start power logging\n        logger.start()\n        time.sleep(0.3)  # Brief stabilization\n        \n        # Run inference through this layer\n        torch.cuda.synchronize()\n        start_time = time.perf_counter()\n        \n        with torch.no_grad():\n            for _ in range(num_loops):\n                input_ids, attention_mask = next(batch_iter)\n                \n                if layer_idx == 0:\n                    # Embeddings only\n                    _ = self.model.distilbert.embeddings(input_ids)\n                elif layer_idx <= 6:\n                    # Through transformer block\n                    hidden_states = self.model.distilbert.embeddings(input_ids)\n                    for i in range(layer_idx):\n                        if i < layer_idx - 1:\n                            # Quick pass through previous layers\n                            hidden_states = self.model.distilbert.transformer.layer[i](\n                                hidden_states, attention_mask\n                            )[0]\n                        else:\n                            # Measure this specific layer\n                            hidden_states = self.model.distilbert.transformer.layer[i](\n                                hidden_states, attention_mask\n                            )[0]\n                else:\n                    # Classifier layers\n                    outputs = self.model.distilbert(input_ids, attention_mask=attention_mask)\n                    hidden_state = outputs[0]\n                    pooled_output = hidden_state[:, 0]\n                    if layer_idx == 7:\n                        _ = self.model.pre_classifier(pooled_output)\n                    else:\n                        pooled_output = self.model.pre_classifier(pooled_output)\n                        _ = self.model.classifier(pooled_output)\n        \n        torch.cuda.synchronize()\n        total_time = time.perf_counter() - start_time\n        \n        # Stop power logging\n        power_samples = logger.stop()\n        \n        # Compute metrics\n        if len(power_samples) > 0:\n            avg_power = float(np.mean(power_samples))\n            energy_total = avg_power * total_time\n            energy_per_inference = energy_total / num_loops\n        else:\n            avg_power = 0.0\n            energy_total = 0.0\n            energy_per_inference = 0.0\n        \n        return {\n            'layer_name': layer_name,\n            'layer_idx': layer_idx,\n            'avg_power_w': avg_power,\n            'total_time_s': total_time,\n            'energy_total_j': energy_total,\n            'energy_per_inference_mj': energy_per_inference * 1000,\n            'num_loops': num_loops,\n            'latency_per_loop_ms': (total_time / num_loops) * 1000,\n            'num_power_samples': len(power_samples)\n        }\n    \n    def profile_all_layers(\n        self,\n        input_ids,\n        attention_mask,\n        batch_size: int = 16,\n        num_loops: int = 100\n    ) -> List[Dict]:\n        \"\"\"\n        Profile energy consumption for all layers.\n        \n        Returns:\n            List of dicts with energy metrics per layer\n        \"\"\"\n        results = []\n        \n        print(\"\\n\" + \"=\"*70)\n        print(\"PER-LAYER ENERGY PROFILING\")\n        print(\"=\"*70)\n        print(f\"Configuration:\")\n        print(f\"  Batch size: {batch_size}\")\n        print(f\"  Loops per layer: {num_loops}\")\n        print(f\"  Total layers: {len(self.layer_names)}\")\n        \n        for layer_idx in range(len(self.layer_names)):\n            # Create iterator for this layer\n            batch_iter = batched_iterator(input_ids, attention_mask, batch_size)\n            \n            # Measure this layer\n            layer_result = self.measure_layer_energy(\n                batch_iter,\n                layer_idx,\n                num_loops=num_loops\n            )\n            \n            results.append(layer_result)\n            \n            # Print result\n            print(f\"    ‚úì {layer_result['layer_name']:25s}: \"\n                  f\"{layer_result['energy_per_inference_mj']:.3f} mJ, \"\n                  f\"{layer_result['latency_per_loop_ms']:.3f} ms, \"\n                  f\"{layer_result['avg_power_w']:.2f} W\")\n            \n            # Small delay between layers\n            time.sleep(0.5)\n        \n        print(\"=\"*70)\n        \n        return results\n\n\ndef visualize_layer_energy(layer_results: List[Dict]):\n    \"\"\"Create visualization of per-layer energy consumption.\"\"\"\n    import matplotlib.pyplot as plt\n    \n    layer_names = [r['layer_name'] for r in layer_results]\n    energies = [r['energy_per_inference_mj'] for r in layer_results]\n    latencies = [r['latency_per_loop_ms'] for r in layer_results]\n    \n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n    \n    # Energy plot\n    ax1.barh(layer_names, energies, color='steelblue')\n    ax1.set_xlabel('Energy per Inference (mJ)')\n    ax1.set_title('Per-Layer Energy Consumption')\n    ax1.grid(axis='x', alpha=0.3)\n    \n    # Latency plot\n    ax2.barh(layer_names, latencies, color='coral')\n    ax2.set_xlabel('Latency (ms)')\n    ax2.set_title('Per-Layer Latency')\n    ax2.grid(axis='x', alpha=0.3)\n    \n    plt.tight_layout()\n    return fig\n\n\nprint(\"‚úì LayerEnergyProfiler class defined\")\nprint(\"‚úì Per-layer profiling functions ready\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## EXPERIMENT: FP32 Per-Layer Energy Profiling\n\nRun this to measure energy consumption for each layer individually.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Per-layer energy profiling for FP32\nprint(\"=\"*70)\nprint(\"FP32 PER-LAYER ENERGY PROFILING\")\nprint(\"=\"*70)\n\n# Load dataset\ninput_ids, attention_mask, labels = load_pre_tokenized_dataset(\n    config.dataset_path, config.device\n)\n\n# Load model\nfp32_model = load_model(\"fp32\", config.model_name, config.device)\n\n# Create profiler\nprofiler = LayerEnergyProfiler(fp32_model, device=config.device)\n\n# Warmup\nprint(\"\\nWarming up...\")\nbatch_iter = batched_iterator(input_ids, attention_mask, config.batch_size)\nwith torch.no_grad():\n    for i in range(10):\n        input_ids_batch, attention_mask_batch = next(batch_iter)\n        _ = fp32_model(input_ids_batch, attention_mask=attention_mask_batch)\ntorch.cuda.synchronize()\nprint(\"‚úì Warmup complete\")\n\n# Profile all layers\nlayer_results_fp32 = profiler.profile_all_layers(\n    input_ids,\n    attention_mask,\n    batch_size=config.batch_size,\n    num_loops=100  # 100 loops per layer for good statistics\n)\n\n# Display results\nprint(\"\\n\" + \"=\"*70)\nprint(\"PER-LAYER RESULTS SUMMARY\")\nprint(\"=\"*70)\n\ndf_layers = pd.DataFrame(layer_results_fp32)\nprint(df_layers[['layer_name', 'energy_per_inference_mj', 'latency_per_loop_ms', 'avg_power_w']])\n\n# Calculate percentages\ntotal_energy = df_layers['energy_per_inference_mj'].sum()\ndf_layers['energy_pct'] = (df_layers['energy_per_inference_mj'] / total_energy * 100).round(2)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ENERGY BREAKDOWN BY LAYER\")\nprint(\"=\"*70)\nfor _, row in df_layers.iterrows():\n    print(f\"  {row['layer_name']:25s}: {row['energy_per_inference_mj']:6.3f} mJ ({row['energy_pct']:5.2f}%)\")\n\nprint(f\"\\n  {'TOTAL':25s}: {total_energy:6.3f} mJ (100.00%)\")\nprint(\"=\"*70)\n\n# Visualize\nfig = visualize_layer_energy(layer_results_fp32)\nplt.savefig('/kaggle/working/energy_results/fp32_per_layer_energy.png', dpi=150, bbox_inches='tight')\nprint(\"\\n‚úì Visualization saved to: /kaggle/working/energy_results/fp32_per_layer_energy.png\")\n\n# Save results\ndf_layers.to_csv('/kaggle/working/energy_results/fp32_per_layer_energy.csv', index=False)\nprint(\"‚úì Results saved to: /kaggle/working/energy_results/fp32_per_layer_energy.csv\")\n\n# Cleanup\ndel fp32_model\ntorch.cuda.empty_cache()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 8: Aggregate Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_trials(trial_results: List[Dict]) -> Dict:\n",
    "    \"\"\"Aggregate metrics across trials.\"\"\"\n",
    "    if not trial_results:\n",
    "        raise ValueError(\"No trial results\")\n",
    "    \n",
    "    metrics_keys = [\n",
    "        'avg_power_w', 'energy_per_inference_j', 'energy_per_inference_mj',\n",
    "        'latency_per_sample_s', 'latency_per_sample_ms', 'throughput_samples_s'\n",
    "    ]\n",
    "    \n",
    "    aggregated = {\n",
    "        'precision': trial_results[0]['precision'],\n",
    "        'batch_size': trial_results[0]['batch_size'],\n",
    "        'seq_len': trial_results[0]['seq_len'],\n",
    "        'num_trials': len(trial_results)\n",
    "    }\n",
    "    \n",
    "    for key in metrics_keys:\n",
    "        values = [r[key] for r in trial_results]\n",
    "        aggregated[f'{key}_mean'] = float(np.mean(values))\n",
    "        aggregated[f'{key}_std'] = float(np.std(values))\n",
    "        aggregated[f'{key}_min'] = float(np.min(values))\n",
    "        aggregated[f'{key}_max'] = float(np.max(values))\n",
    "    \n",
    "    return aggregated\n",
    "\n",
    "\n",
    "print(\"‚úì Aggregation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1: Test with FP32 (Small Scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Quick test - 1 trial, reduced loops to match available data\n# Use this to debug PowerLogger\n\ntest_config = ExperimentConfig(\n    batch_size=16,\n    num_loops=50,  # 50 loops √ó 16 batch = 800 samples (8x reuse with 100 samples)\n    warmup_loops=10,\n    num_trials=1\n)\n\nprint(\"Running QUICK TEST (1 trial, 50 loops, batch_size=16)...\")\nprint(f\"Total samples: {test_config.num_loops * test_config.batch_size}\")\ntest_results = run_experiments_for_precision(test_config, \"fp32\", num_trials=1)\n\nif test_results:\n    print(\"\\n\" + \"=\"*70)\n    print(\"‚úì TEST SUCCESSFUL\")\n    print(\"=\"*70)\n    print(\"PowerLogger is working! Proceed to full experiments.\")\nelse:\n    print(\"\\n\" + \"=\"*70)\n    print(\"‚úó TEST FAILED\")\n    print(\"=\"*70)\n    print(\"Fix PowerLogger before proceeding.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 2: Full FP32 (5 Trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Full FP32 experiment\n# Run this after test succeeds\n\nfull_config = ExperimentConfig(\n    batch_size=32,  # Increased from 8\n    num_loops=1000,  # Increased from 200\n    warmup_loops=100,  # Increased from 50\n    num_trials=5\n)\n\nprint(\"Running FULL FP32 EXPERIMENT (5 trials, 1000 loops, batch_size=32)...\")\nprint(\"Total samples per trial: 1000 √ó 32 = 32,000 samples\")\nprint(\"This will take ~10-15 minutes\")\nprint(\"=\"*70)\n\nfp32_results = run_experiments_for_precision(full_config, \"fp32\", num_trials=5)\n\n# Aggregate\nif fp32_results:\n    fp32_agg = aggregate_trials(fp32_results)\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"FP32 AGGREGATED RESULTS (5 trials)\")\n    print(\"=\"*70)\n    print(f\"Latency:    {fp32_agg['latency_per_sample_ms_mean']:.3f} ¬± {fp32_agg['latency_per_sample_ms_std']:.3f} ms\")\n    print(f\"Throughput: {fp32_agg['throughput_samples_s_mean']:.2f} ¬± {fp32_agg['throughput_samples_s_std']:.2f} samples/s\")\n    print(f\"Avg Power:  {fp32_agg['avg_power_w_mean']:.2f} ¬± {fp32_agg['avg_power_w_std']:.2f} W\")\n    print(f\"Energy:     {fp32_agg['energy_per_inference_mj_mean']:.3f} ¬± {fp32_agg['energy_per_inference_mj_std']:.3f} mJ\")\n    print(\"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 3: FP16 (When Thomas Provides Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when Thomas provides FP16 model\n",
    "\n",
    "# fp16_results = run_experiments_for_precision(full_config, \"fp16\", num_trials=5)\n",
    "\n",
    "# if fp16_results:\n",
    "#     fp16_agg = aggregate_trials(fp16_results)\n",
    "#     \n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "#     print(\"FP16 AGGREGATED RESULTS\")\n",
    "#     print(\"=\"*70)\n",
    "#     print(f\"Latency:    {fp16_agg['latency_per_sample_ms_mean']:.3f} ¬± {fp16_agg['latency_per_sample_ms_std']:.3f} ms\")\n",
    "#     print(f\"Throughput: {fp16_agg['throughput_samples_s_mean']:.2f} ¬± {fp16_agg['throughput_samples_s_std']:.2f} samples/s\")\n",
    "#     print(f\"Avg Power:  {fp16_agg['avg_power_w_mean']:.2f} ¬± {fp16_agg['avg_power_w_std']:.2f} W\")\n",
    "#     print(f\"Energy:     {fp16_agg['energy_per_inference_mj_mean']:.3f} ¬± {fp16_agg['energy_per_inference_mj_std']:.3f} mJ\")\n",
    "\n",
    "print(\"FP16 experiment ready (currently commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 4: INT8 (When Thomas Provides Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment when Thomas provides INT8 model\n",
    "\n",
    "# int8_results = run_experiments_for_precision(full_config, \"int8\", num_trials=5)\n",
    "\n",
    "# if int8_results:\n",
    "#     int8_agg = aggregate_trials(int8_results)\n",
    "#     \n",
    "#     print(\"\\n\" + \"=\"*70)\n",
    "#     print(\"INT8 AGGREGATED RESULTS\")\n",
    "#     print(\"=\"*70)\n",
    "#     print(f\"Latency:    {int8_agg['latency_per_sample_ms_mean']:.3f} ¬± {int8_agg['latency_per_sample_ms_std']:.3f} ms\")\n",
    "#     print(f\"Throughput: {int8_agg['throughput_samples_s_mean']:.2f} ¬± {int8_agg['throughput_samples_s_std']:.2f} samples/s\")\n",
    "#     print(f\"Avg Power:  {int8_agg['avg_power_w_mean']:.2f} ¬± {int8_agg['avg_power_w_std']:.2f} W\")\n",
    "#     print(f\"Energy:     {int8_agg['energy_per_inference_mj_mean']:.3f} ¬± {int8_agg['energy_per_inference_mj_std']:.3f} mJ\")\n",
    "\n",
    "print(\"INT8 experiment ready (currently commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save aggregated results\n",
    "output_dir = Path('/kaggle/working/energy_results')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Collect all aggregated results\n",
    "all_agg_results = []\n",
    "\n",
    "if 'fp32_agg' in locals():\n",
    "    all_agg_results.append(fp32_agg)\n",
    "\n",
    "# if 'fp16_agg' in locals():\n",
    "#     all_agg_results.append(fp16_agg)\n",
    "\n",
    "# if 'int8_agg' in locals():\n",
    "#     all_agg_results.append(int8_agg)\n",
    "\n",
    "if all_agg_results:\n",
    "    # Save as CSV\n",
    "    df_agg = pd.DataFrame(all_agg_results)\n",
    "    df_agg.to_csv(output_dir / 'energy_results_aggregated.csv', index=False)\n",
    "    print(f\"‚úì Saved: {output_dir / 'energy_results_aggregated.csv'}\")\n",
    "    \n",
    "    # Save as JSON\n",
    "    with open(output_dir / 'energy_results_aggregated.json', 'w') as f:\n",
    "        json.dump(all_agg_results, f, indent=2)\n",
    "    print(f\"‚úì Saved: {output_dir / 'energy_results_aggregated.json'}\")\n",
    "    \n",
    "    # Display\n",
    "    print(\"\\nResults Table:\")\n",
    "    display(df_agg[['precision', 'latency_per_sample_ms_mean', 'avg_power_w_mean', 'energy_per_inference_mj_mean']])\n",
    "else:\n",
    "    print(\"No results to save yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Taara's Accuracy Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate latency matches Taara's results\n",
    "if 'fp32_agg' in locals():\n",
    "    print(\"Validation Check:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Your FP32 latency:  {fp32_agg['latency_per_sample_ms_mean']:.3f} ms\")\n",
    "    print(f\"Taara's FP32 latency: 2.32 ms (from 0.116s / 50 samples)\")\n",
    "    \n",
    "    diff_pct = abs(fp32_agg['latency_per_sample_ms_mean'] - 2.32) / 2.32 * 100\n",
    "    print(f\"Difference: {diff_pct:.1f}%\")\n",
    "    \n",
    "    if diff_pct < 10:\n",
    "        print(\"‚úì Latencies match within 10% - validation passed!\")\n",
    "    else:\n",
    "        print(\"‚ö† Latencies differ by >10% - check configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions (Save Config, Merge with Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_config_to_file(config: ExperimentConfig, output_path: str):\n",
    "    \"\"\"Save configuration to JSON file.\"\"\"\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(asdict(config), f, indent=2)\n",
    "    print(f\"‚úì Config saved to {output_path}\")\n",
    "\n",
    "\n",
    "def merge_with_accuracy_results(energy_results: Dict, accuracy_results_path: str) -> Dict:\n",
    "    \"\"\"Merge energy results with Taara's accuracy results.\"\"\"\n",
    "    with open(accuracy_results_path, 'r') as f:\n",
    "        acc_results = json.load(f)\n",
    "    \n",
    "    merged = {**energy_results, **acc_results}\n",
    "    return merged\n",
    "\n",
    "\n",
    "# Save current config\n",
    "save_config_to_file(config, '/kaggle/working/energy_results/experiment_config.json')\n",
    "\n",
    "print(\"\\n‚úì Utility functions defined\")\n",
    "print(\"  - save_config_to_file(): Save experiment config\")\n",
    "print(\"  - merge_with_accuracy_results(): Merge with Taara's data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Energy + Accuracy (After Both Complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this after energy experiments complete and Taara has accuracy results\n",
    "\n",
    "# Example: Merge FP32 energy with FP32 accuracy\n",
    "# if 'fp32_agg' in locals():\n",
    "#     merged_fp32 = merge_with_accuracy_results(\n",
    "#         energy_results=fp32_agg,\n",
    "#         accuracy_results_path='/kaggle/working/results/fp32_baseline.json'\n",
    "#     )\n",
    "#     \n",
    "#     print(\"\\nMerged FP32 Results:\")\n",
    "#     print(\"=\"*60)\n",
    "#     print(f\"  Accuracy:   {merged_fp32['accuracy']*100:.2f}%\")\n",
    "#     print(f\"  Latency:    {merged_fp32['latency_per_sample_ms_mean']:.3f} ms\")\n",
    "#     print(f\"  Power:      {merged_fp32['avg_power_w_mean']:.2f} W\")\n",
    "#     print(f\"  Energy:     {merged_fp32['energy_per_inference_mj_mean']:.3f} mJ\")\n",
    "#     print(\"=\"*60)\n",
    "\n",
    "print(\"Merge function ready (currently commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENERGY MEASUREMENT HARNESS - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nCompleted Experiments:\")\n",
    "if 'fp32_results' in locals() and fp32_results:\n",
    "    print(\"  ‚úì FP32: 5 trials complete\")\n",
    "else:\n",
    "    print(\"  ‚óã FP32: Not run yet\")\n",
    "\n",
    "# if 'fp16_results' in locals() and fp16_results:\n",
    "#     print(\"  ‚úì FP16: 5 trials complete\")\n",
    "# else:\n",
    "print(\"  ‚óã FP16: Waiting for Thomas\")\n",
    "\n",
    "# if 'int8_results' in locals() and int8_results:\n",
    "#     print(\"  ‚úì INT8: 5 trials complete\")\n",
    "# else:\n",
    "print(\"  ‚óã INT8: Waiting for Thomas\")\n",
    "\n",
    "print(\"\\nOutput Files:\")\n",
    "if (output_dir / 'energy_results_aggregated.csv').exists():\n",
    "    print(f\"  ‚úì {output_dir / 'energy_results_aggregated.csv'}\")\n",
    "    print(f\"  ‚úì {output_dir / 'energy_results_aggregated.json'}\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Share energy results with Taara\")\n",
    "print(\"  2. Taara will merge with accuracy results\")\n",
    "print(\"  3. Generate comparison plots\")\n",
    "print(\"  4. Write report\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Krishna: Great work!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}